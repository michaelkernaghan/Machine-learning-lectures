<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.tailwindcss.com" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
    <title>Comprehensive Learning Path for Machine Learning and Deep Learning</title>
    <style>
        table {
            width: 100%;
            border-collapse: collapse;
        }

        th,
        td {
            border: 1px solid black;
            padding: 8px;
            text-align: left;
        }

        th {
            background-color: #f2f2f2;
        }
    </style>
</head>

<body>
    <header class="bg-gray-800 text-white p-4">
        <nav>
            <ul class="flex space-x-4">
                <li><a href="index.html" class="text-blue-400">Home</a></li>
                <li><a href="lecture1.html" class="text-blue-400">1</a></li>
                <li><a href="lecture3.html" class="text-blue-400">3</a></li>
                <li><a href="lecture4.html" class="text-blue-400">4</a></li>
                <li><a href="lecture5.html" class="text-blue-400">5</a></li>
                <li><a href="lecture6.html" class="text-blue-400">6</a></li>
                <li><a href="lecture7.html" class="text-blue-400">7</a></li>
                <li><a href="lecture8.html" class="text-blue-400">8</a></li>
            </ul>
        </nav>
        <h1>2: Learning Path for Machine Learning and Deep Learning</h1>
    </header>

    <main class="p-4">
        <img src="./learning-path.png" alt="Learning Path" class="section-image">
        <section>
            <h2>Introduction</h2>
            <p>This comprehensive guide outlines a structured learning path from basic to advanced topics in machine learning and deep learning, including transformers and large language models (LLMs).</p>
            <table class="min-w-full divide-y divide-gray-200 mt-4">
                <thead class="bg-gray-50">
                    <tr>
                        <th>Step</th>
                        <th>Description</th>
                        <th>Key Points</th>
                    </tr>
                </thead>
                <tbody class="bg-white divide-y divide-gray-200">
                    <tr>
                        <td>1. Basic Concepts in Machine Learning</td>
                        <td>Understanding Data Types, Supervised vs. Unsupervised Learning, and Evaluation Metrics.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Statistics">Statistical foundations</a>, <a href="https://en.wikipedia.org/wiki/Calculus">basic calculus</a>.</td>
                    </tr>
                    <tr>
                        <td>2. Intermediate Machine Learning</td>
                        <td>Feature Engineering, Model Selection, strategies for Overfitting and Underfitting.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">Regularizations</a>, <a href="https://en.wikipedia.org/wiki/Optimization_(mathematics)">optimization techniques</a>.</td>
                    </tr>
                    <tr>
                        <td>3. Deep Learning</td>
                        <td>Study of Neural Networks, Activation Functions, Backpropagation.</td>
                        <td>Mechanism for training neural networks.</td>
                    </tr>
                    <tr>
                        <td>4. Advanced Deep Learning Concepts</td>
                        <td><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">CNNs</a>, <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">RNNs</a>, <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM</a>, Regularization Techniques.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Dropout_(neural_networks)">Dropout</a>, <a href="https://en.wikipedia.org/wiki/Batch_normalization">Batch Normalization</a>.</td>
                    </tr>
                    <tr>
                        <td>5. Transformers and Attention Mechanisms</td>
                        <td><a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Attention Mechanism</a>, <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">Transformer Architecture</a>, <a href="https://en.wikipedia.org/wiki/BERT_(language_model)">BERT</a> and <a href="https://en.wikipedia.org/wiki/GPT-3">GPT Models</a>.</td>
                        <td>Pre-training and fine-tuning methodologies.</td>
                    </tr>
                    <tr>
                        <td>6. Large Language Models (LLMs)</td>
                        <td>Scaling and Training Challenges, Applications, Ethics and Bias in AI.</td>
                        <td>Advanced topics in <a href="https://en.wikipedia.org/wiki/Bayesian_neural_network">Bayesian Neural Networks</a>.</td>
                    </tr>
                    <tr>
                        <td>Resources and Practical Experience</td>
                        <td colspan="2">Books, courses, practical projects, and participation in competitions.</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Summary and Comparison of Machine Learning Paradigms</h2>
            <table>
                <thead>
                    <tr>
                        <th>Aspect</th>
                        <th>Supervised Learning</th>
                        <th>Unsupervised Learning</th>
                        <th>Reinforcement Learning</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Data</td>
                        <td><a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">Labeled data (input-output pairs)</a></td>
                        <td><a href="https://en.wikipedia.org/wiki/Unsupervised_learning">Unlabeled data</a></td>
                        <td><a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Feedback from the environment (rewards)</a></td>
                    </tr>
                    <tr>
                        <td>Goal</td>
                        <td>Predict output from given input</td>
                        <td>Discover structure in data</td>
                        <td>Learn a policy to maximize rewards</td>
                    </tr>
                    <tr>
                        <td>Examples</td>
                        <td><a href="https://en.wikipedia.org/wiki/Statistical_classification">Classification</a>, <a href="https://en.wikipedia.org/wiki/Regression_analysis">Regression</a></td>
                        <td><a href="https://en.wikipedia.org/wiki/Cluster_analysis">Clustering</a>, <a href="https://en.wikipedia.org/wiki/Dimensionality_reduction">Dimensionality Reduction</a></td>
                        <td><a href="https://en.wikipedia.org/wiki/Game_artificial_intelligence">Game AI</a>, <a href="https://en.wikipedia.org/wiki/Robotics">Robotics</a></td>
                    </tr>
                    <tr>
                        <td>Algorithms</td>
                        <td><a href="https://en.wikipedia.org/wiki/Linear_regression">Linear Regression</a>, <a href="https://en.wikipedia.org/wiki/Decision_tree">Decision Trees</a></td>
                        <td><a href="https://en.wikipedia.org/wiki/K-means_clustering">K-means</a>, <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a></td>
                        <td><a href="https://en.wikipedia.org/wiki/Q-learning">Q-learning</a>, <a href="https://en.wikipedia.org/wiki/Policy_gradient">Policy Gradient</a></td>
                    </tr>
                    <tr>
                        <td>Challenges</td>
                        <td>Overfitting, Need for labeled data</td>
                        <td>Harder to evaluate, No definite feedback</td>
                        <td>Requires lots of computation, Delayed feedback</td>
                    </tr>
                    <tr>
                        <td>Feedback</td>
                        <td>Direct feedback (error signals)</td>
                        <td>No feedback</td>
                        <td>Indirect/delayed feedback</td>
                    </tr>
                    <tr>
                        <td>Dependency</td>
                        <td>Dependent on quality and quantity of labels</td>
                        <td>Less dependent on external data, more on dataâ€™s intrinsic structure</td>
                        <td>Depends on the environment setup and reward structure</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Intermediate Machine Learning</h2>
            <table class="min-w-full divide-y divide-gray-200 mt-4">
                <thead class="bg-gray-50">
                    <tr>
                        <th>Intermediate Machine Learning Topics</th>
                        <th>Description</th>
                        <th>Techniques/Methods</th>
                    </tr>
                </thead>
                <tbody class="bg-white divide-y divide-gray-200">
                    <tr>
                        <td>Feature Engineering</td>
                        <td>Techniques for data preprocessing and transformation to improve model accuracy and efficiency.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">Normalization</a>, <a href="https://en.wikipedia.org/wiki/Feature_scaling">Scaling</a>, <a href="https://en.wikipedia.org/wiki/One-hot">Encoding Categorical Data</a>, <a href="https://en.wikipedia.org/wiki/Feature_selection">Feature Selection</a></td>
                    </tr>
                    <tr>
                        <td>Model Selection</td>
                        <td>Evaluating and choosing the right model based on predictive performance.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">Cross-validation</a>, <a href="https://en.wikipedia.org/wiki/Grid_search">Grid Search</a>, <a href="https://en.wikipedia.org/wiki/Random_search">Random Search</a>, <a href="https://en.wikipedia.org/wiki/Model_selection">Model Comparison Metrics</a></td>
                    </tr>
                    <tr>
                        <td>Overfitting and Underfitting</td>
                        <td>Strategies to balance model complexity and performance to prevent overfitting or underfitting.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)#L1_regularization">Regularization Techniques (L1</a>, <a href="https://en.wikipedia.org/wiki/Tikhonov_regularization">L2)</a>, <a href="https://en.wikipedia.org/wiki/Early_stopping">Early Stopping</a>, <a href="https://en.wikipedia.org/wiki/Pruning_(machine_learning)">Pruning</a></td>
                    </tr>
                    <tr>
                        <td>Optimization Techniques</td>
                        <td>Methods to improve the speed and accuracy of learning in machine learning models.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient Descent</a>, <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent</a>, <a href="https://en.wikipedia.org/wiki/Adam_(optimization_algorithm)">Adam Optimizer</a></td>
                    </tr>
                    <tr>
                        <td>Regularization</td>
                        <td>Techniques used to reduce the model complexity and prevent overfitting.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Dropout_(neural_networks)">Dropout</a>, <a href="https://en.wikipedia.org/wiki/Tikhonov_regularization">Ridge</a>, <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)#L1_regularization">Lasso</a></td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Deep Learning</h2>
            <table class="min-w-full divide-y divide-gray-200 mt-4">
                <thead class="bg-gray-50">
                    <tr>
                        <th>Deep Learning Topics</th>
                        <th>Description</th>
                        <th>Key Concepts and Techniques</th>
                    </tr>
                </thead>
                <tbody class="bg-white divide-y divide-gray-200">
                    <tr>
                        <td>Neural Networks</td>
                        <td>Frameworks of nodes (neurons) connected together to simulate a simplistic model of how the human brain works to solve specific tasks.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">Feedforward NN</a>, <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional NN</a>, <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent NN</a></td>
                    </tr>
                    <tr>
                        <td>Activation Functions</td>
                        <td>Functions that decide whether a neuron should be activated or not, influencing the output of the network.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid</a>, <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a>, <a href="https://en.wikipedia.org/wiki/Hyperbolic_function#Hyperbolic_tangent">Tanh</a>, <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Leaky_ReLU">Leaky ReLU</a></td>
                    </tr>
                    <tr>
                        <td>Backpropagation</td>
                        <td>The method used to update the weights of the neural network through gradient descent, optimizing the loss function.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Chain_rule">Chain Rule</a>, <a href="https://en.wikipedia.org/wiki/Learning_rate">Learning Rate</a>, <a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient Descent</a></td>
                    </tr>
                    <tr>
                        <td>Training Neural Networks</td>
                        <td>Process of feeding data into the network and adjusting weights via backpropagation based on the error rate of the output compared to the true label.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Batch_training">Batch Training</a>, <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">Stochastic Gradient Descent</a>, <a href="https://en.wikipedia.org/wiki/Overfitting">Overfitting Prevention</a></td>
                    </tr>
                </tbody>
            </table>
        </section>

        <section>
            <h2>Blockchain Technology and Machine Learning</h2>
            <table class="min-w-full divide-y divide-gray-200 mt-4">
                <thead class="bg-gray-50">
                    <tr>
                        <th>Intersection Topics</th>
                        <th>Description</th>
                        <th>Key Concepts and Technologies</th>
                    </tr>
                </thead>
                <tbody class="bg-white divide-y divide-gray-200">
                    <tr>
                        <td>Decentralized NLP Datasets</td>
                        <td>Using blockchain to manage and verify the integrity of datasets used in NLP, ensuring data quality and provenance.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Smart_contract">Smart Contracts</a>, <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a>, <a href="https://en.wikipedia.org/wiki/Data_tokenization">Data Tokenization</a></td>
                    </tr>
                    <tr>
                        <td>Decentralized Machine Learning Models</td>
                        <td>Distributing the training of machine learning models across multiple blockchain nodes to enhance privacy and data security.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Federated_learning">Federated Learning</a>, <a href="https://en.wikipedia.org/wiki/Ethereum">Ethereum</a>, <a href="https://en.wikipedia.org/wiki/Blockchain_consensus">Blockchain Consensus Algorithms</a></td>
                    </tr>
                    <tr>
                        <td>Transparent Model Training</td>
                        <td>Leveraging blockchain to log and verify each step in the training of NLP models, making the process transparent and auditable.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Blockchain">Blockchain Audits</a>, <a href="https://en.wikipedia.org/wiki/Chain_of_custody">Chain of Custody in Data</a>, <a href="https://en.wikipedia.org/wiki/Oracle_machine">Smart Contract Oracles</a></td>
                    </tr>
                    <tr>
                        <td>Secure Multi-Party Computation</td>
                        <td>Using blockchain to facilitate secure, multi-party computations for NLP tasks, ensuring confidentiality and integrity without central authority.</td>
                        <td><a href="https://en.wikipedia.org/wiki/Zero-knowledge_proof">Zero-Knowledge Proofs</a>, <a href="https://en.wikipedia.org/wiki/Homomorphic_encryption">Homomorphic Encryption</a>, <a href="https://en.wikipedia.org/wiki/Secure_multi-party_computation">Secure Protocols</a></td>
                    </tr>
                </tbody>
            </table>
        </section>
    </main>

    <footer class="bg-gray-800 text-white p-4">
        <nav>
            <ul class="flex space-x-4">
                <li><a href="index.html" class="text-blue-400">Home</a></li>
                <li><a href="lecture1.html" class="text-blue-400">1</a></li>
                <li><a href="lecture3.html" class="text-blue-400">3</a></li>
                <li><a href="lecture4.html" class="text-blue-400">4</a></li>
                <li><a href="lecture5.html" class="text-blue-400">5</a></li>
                <li><a href="lecture6.html" class="text-blue-400">6</a></li>
                <li><a href="lecture7.html" class="text-blue-400">7</a></li>
                <li><a href="lecture8.html" class="text-blue-400">8</a></li>
            </ul>
        </nav>
    </footer>
</body>

</html>
