<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.tailwindcss.com" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
    <title>3: Historical Timeline of Machine Learning</title>
</head>

<body>
    <header class="bg-gray-800 text-white p-4">
        <nav>
            <ul class="flex space-x-4">
                <li><a href="index.html" class="text-blue-400">Home</a></li>
                <li><a href="lecture1.html" class="text-blue-400">1</a></li>
                <li><a href="lecture2.html" class="text-blue-400">2</a></li>
                <li><a href="lecture4.html" class="text-blue-400">4</a></li>
                <li><a href="lecture5.html" class="text-blue-400">5</a></li>
                <li><a href="lecture6.html" class="text-blue-400">6</a></li>
                <li><a href="lecture7.html" class="text-blue-400">7</a></li>
                <li><a href="lecture8.html" class="text-blue-400">8</a></li>
            </ul>
        </nav>
        <h1>3: Historical Timeline of Machine Learning</h1>
    </header>
    <p></p>
    <main class="p-4">
        <section>
            <p>Explore the key milestones in the evolution of machine learning from its inception to the present day.
            </p>

            <h3>Timeline of Key Developments</h3>
            <ul>
                <li><strong>1950s</strong> - Early Foundations:
                    <ul>
                        <li>1950: Alan Turing publishes "Computing Machinery and Intelligence," proposing what is now
                            called the Turing Test.</li>
                        <li>1952: Arthur Samuel develops the first computer learning program, which was a game of
                            checkers.</li>

                    </ul>
                </li>
                <img src="../images/graphs/perceptron-1961.png" alt="Perceptron" class="section-image">
                <p></p>
                <li><strong>1960s</strong> - Concept of Neural Networks:
                    <ul>
                        <li>1961: The first step toward modern AI as Frank Rosenblatt proposes the Perceptron, an early
                            neural network.</li>
                        <li>1967: The nearest neighbor algorithm was written, which allowed computers to begin using
                            basic pattern recognition.</li>
                    </ul>
                    <h3>How Neural Nets Work</h3>
                    <a href="perceptron.html" class="text-blue-400">The Perceptron Explained</a> is a page with examples
                    and a simple neural network code sample</h3>

                    <p></p>
                <li><strong>1980s</strong> - Revival and Expansion:
                    <ul>
                        <li>1980: The concept of backpropagation is popularized by Geoffrey Hinton and others, improving
                            training for multi-layer networks.</li>
                        <li>1985: Terry Sejnowski and Charles Rosenberg develop NetTalk, which learns to pronounce
                            English text aloud using a neural network.</li>
                    </ul>
                </li>
                <p></p>
                <li><strong>1990s</strong> - Support Vector Machines and Advances in Theory:
                    <ul>
                        <li>1995: Support Vector Machines (SVMs) are developed, providing a new generation of learning
                            algorithms.</li>
                        <li>1997: Long Short-Term Memory (LSTM) networks are introduced by Hochreiter & Schmidhuber,
                            which significantly improve recurrent neural network capabilities.</li>
                    </ul>
                </li>
                <img src="../images/graphs/svms-1990s.png" alt="SVMs" class="section-image">
                <p></p>
                <li><strong>2000s</strong> - The Era of Big Data:
                    <ul>
                        <li>2006: Geoffrey Hinton et al. introduce concepts of deep learning in neural networks with
                            deep architectures.</li>
                        <li>2009: Fei-Fei Li launches ImageNet, a large visual database designed for use in visual
                            object recognition software research.</li>
                    </ul>
                </li>
                <p></p>
                <li><strong>2010s</strong> - Deep Learning Breakthroughs:
                    <ul>
                        <li>2012: AlexNet wins the ImageNet challenge, significantly outperforming the second-place
                            competitor, which catalyzes the focus on deep learning in the AI community.</li>
                        <li>2016: Google's AlphaGo defeats Lee Sedol in Go, a milestone for AI in complex problem
                            solving.</li>
                    </ul>
                </li>
                <p></p>
                <li><strong>2017</strong> - Transformers Revolution:
                    <ul>
                        <li>2017: The paper "Attention Is All You Need" by Vaswani et al. is published, introducing the
                            transformer model, which uses self-attention mechanisms to significantly improve the
                            efficiency of training language models.</li>
                    </ul>
                </li>
                <img src="../images/graphs/transformer-2017.png" alt="Transformer" class="section-image">
                <p></p>
                <li><strong>2018</strong> - Advancements in Natural Language Processing:
                    <ul>
                        <li>2018: BERT (Bidirectional Encoder Representations from Transformers) is developed by
                            researchers at Google. This model sets new standards for a variety of NLP tasks, including
                            question answering and language inference.</li>
                    </ul>
                </li>
                <p></p>
                <li><strong>2019</strong> - GPT-2 and the Rise of Generative Models:
                    <ul>
                        <li>2019: OpenAI introduces GPT-2, a large transformer-based language model known for its
                            ability to generate coherent and contextually relevant text on a wide range of topics.</li>
                    </ul>
                </li>
                <p></p>
                <li><strong>2020</strong> - AI Ethics and Regulation:
                    <ul>
                        <li>2020: AI regulation begins to take shape with the European Union proposing the first legal
                            framework for ethical AI use, focusing on transparency, accountability, and accuracy.</li>
                    </ul>
                </li>
                <p></p>
                <li><strong>2021</strong> - Foundation Models:
                    <ul>
                        <li>2021: The concept of foundation models is proposed, characterized by large-scale models
                            trained on broad data at scale that are adaptable to a wide range of tasks.</li>
                    </ul>
                </li>
                <p></p>
                <li><strong>2022</strong> - Advances in Multimodal AI:
                    <ul>
                        <li>2022: AI models that can understand and generate multiple forms of data (text, image, video)
                            simultaneously become more prevalent, enhancing capabilities in applications from autonomous
                            vehicles to content creation.</li>
                    </ul>
                </li>
                <img src="../images/models/personalized-2024.png" alt="Personalized" class="section-image">
                <p></p>
                <li><strong>2024</strong> - Personalized AI:
                    <ul>
                        <li>2024: Advancements in personalized AI systems provide customized health diagnostics,
                            learning supports, and financial advice, making artificial intelligence more directly
                            applicable to individual daily needs.</li>

                    </ul>
                </li>
            </ul>
        </section>
    </main>
    <p></p>
    <footer>
        <nav>
            <ul class="bg-gray-800 text-white p-4">
                <li><a href="index.html" class="text-blue-400">Home</a></li>
                <li><a href="lecture1.html" class="text-blue-400">1</a></li>
                <li><a href="lecture2.html" class="text-blue-400">2</a></li>
                <li><a href="lecture4.html" class="text-blue-400">4</a></li>
                <li><a href="lecture5.html" class="text-blue-400">5</a></li>
                <li><a href="lecture6.html" class="text-blue-400">6</a></li>
                <li><a href="lecture7.html" class="text-blue-400">7</a></li>
                <li><a href="lecture8.html" class="text-blue-400">8</a></li>
            </ul>
        </nav>
    </footer>
</body>
</html>
