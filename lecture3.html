<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://cdn.tailwindcss.com" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
    <title>Lecture 3: Key Concepts in Machine Learning</title>
</head>
<body>
    <header class="bg-gray-800 text-white p-4">
        <nav>
            <ul class="flex space-x-4">
                <li><a href="index.html" class="text-blue-400">Home</a></li>
                <li><a href="lecture1.html" class="text-blue-400">Lecture 1</a></li>
                <li><a href="lecture2.html" class="text-blue-400">Lecture 2</a></li>
                <li><a href="lecture4.html" class="text-blue-400">Lecture 4</a></li>
                <li><a href="lecture5.html" class="text-blue-400">Lecture 5</a></li>
                <li><a href="lecture6.html" class="text-blue-400">Lecture 6</a></li>
            </ul>
        </nav>
        <h1>Lecture 3: Key Concepts in Machine Learning</h1>
    </header>
    <main class="p-4">
        <section>
            <h2>Key Concepts in Machine Learning</h2>
            <p>This lecture is dedicated to the core concepts that underpin the field of machine learning, focusing on data preprocessing, feature engineering, model selection, and the balancing act of bias and variance.</p>
            
            <h3>Data Preprocessing</h3>
            <ul>
                <li><strong>Cleaning Data:</strong> Techniques include handling missing values and removing outliers.</li>
                <li><strong>Normalizing Data:</strong> Methods such as Min-Max scaling and Z-score normalization adjust the scale of features to a standard range.</li>
                <li><strong>Transforming Data:</strong> Applying logarithmic transformations and other mathematical functions to improve the suitability for modeling.</li>
                <li><strong>Encoding Categorical Data:</strong> Techniques like one-hot encoding and label encoding to convert categories into numbers suitable for modeling.</li>
            </ul>
            
            <h3>Feature Engineering</h3>
            <p>A feature is an individual measurable property or characteristic of a phenomenon being observed. In machine learning, features are used as input variables to models.</p>
            <ul>
                <li><strong>Creation of Interaction Terms:</strong> Captures interactions between variables to improve model predictions.</li>
                <li><strong>Polynomial Features:</strong> Deriving new features by considering polynomial combinations of existing features, which can expose more complex relationships in data.</li>
                <li><strong>Domain-specific Aggregations:</strong> Summarizing data by creating averages, sums, or other statistical aggregations specific to the domain to highlight important trends.</li>
                <li><strong>Advanced Techniques:</strong> Including feature selection algorithms to identify significant features and dimensionality reduction to simplify the feature space without losing critical information.</li>
            </ul>
            
            <h3>Model Selection</h3>
            <ul>
                <li><strong>Criteria for Selection:</strong> Includes accuracy, interpretability, training time, and complexity.</li>
                <li><strong>Comparative Analysis:</strong> Evaluating models like SVM, decision trees, and neural networks to determine their effectiveness for various data types and tasks.</li>
                <li><strong>Model Validation Techniques:</strong> Utilizing k-fold cross-validation and training/validation/test splits to test model robustness and ensure generalizability.</li>
            </ul>
            
            <h3>Overfitting and Underfitting</h3>
            <ul>
                <li><strong>Overfitting:</strong> When a model learns too much detail including noise from the training data, leading to poor performance on new data.</li>
                <li><strong>Underfitting:</strong> When a model is too simple to learn the underlying pattern of the data, resulting in inadequate performance even on the training data.</li>
                <li><strong>Techniques to Combat:</strong> Include cross-validation, regularization (L1 and L2), and pruning of decision trees to enhance model reliability.</li>
                <li><strong>Hyperparameter Tuning:</strong> Using methods like grid search and random search to optimize model parameters for best performance.</li>
            </ul>
            <h3>Evaluation Metrics</h3>
            <ul>
                <li><strong>Accuracy, Precision, and Recall:</strong> Fundamental metrics for classification problems.</li>
                <li><strong>Mean Squared Error and Mean Absolute Error:</strong> Key metrics for regression analysis.</li>
                <li><strong>Confusion Matrix:</strong> A table used to describe the performance of a classification model on a set of test data for which the true values are known.</li>
                <li><strong>AUC-ROC:</strong> The area under the curve of the receiver operating characteristics; a comprehensive measure for evaluating binary classification models.</li>
            </ul>
            
            <h3>Ensemble Methods</h3>
            <ul>
                <li><strong>Boosting:</strong> Combining multiple weak learners to form a strong learner, e.g., AdaBoost, Gradient Boosting.</li>
                <li><strong>Bagging:</strong> Building multiple models (typically of the same type) from different subsamples of the training dataset, e.g., Random Forest.</li>
                <li><strong>Stacking:</strong> Combining multiple classification or regression models via a meta-classifier or a meta-regressor.</li>
            </ul>
            
            <h3>Ethical Considerations and Bias in Machine Learning</h3>
            <ul>
                <li><strong>Algorithmic Bias:</strong> How biases in data or model design can lead to unfair outcomes, such as discrimination against certain groups.</li>
                <li><strong>Data Privacy:</strong> Ensuring that the data used in models does not violate privacy rights and is compliant with regulations like GDPR.</li>
                <li><strong>Model Transparency and Explainability:</strong> Developing models that can be understood and interpreted by humans, important for accountability and trust.</li>
            </ul>
        </section>
    </main>
    <footer class="bg-gray-800 text-white p-4 text-center">
        Â© 2024 Standard Testing <a href="http://standardtesting.io" class="text-blue-400 hover:text-blue-700" target="_blank">standardtesting.io</a>
    </footer>
</body>
</html>
